# -*- coding: utf-8 -*-
"""
í™ˆ CCTV ê°ì²´ ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
YOLOv5 ê¸°ë°˜ 19ê°œ í´ë˜ìŠ¤ ê°ì²´ ì¸ì‹

ì‚¬ìš©ë²•:
1. python test_model.py --image test_image.jpg
2. python test_model.py --video test_video.mp4
3. python test_model.py --webcam  # ì›¹ìº  ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
"""

import cv2
import torch
import numpy as np
import argparse
from pathlib import Path
import time
from ultralytics import YOLO

# í™ˆ CCTV í´ë˜ìŠ¤ ì •ì˜
HOME_CCTV_CLASSES = {
    0: 'person',        # ì‚¬ëŒ
    1: 'cat',           # ê³ ì–‘ì´
    2: 'dog',           # ê°œ
    3: 'knife',         # ì¹¼
    4: 'scissors',      # ê°€ìœ„
    5: 'backpack',      # ë°°ë‚­
    6: 'handbag',       # í•¸ë“œë°±
    7: 'suitcase',      # ì—¬í–‰ê°€ë°©
    8: 'laptop',        # ë…¸íŠ¸ë¶
    9: 'mouse',         # ë§ˆìš°ìŠ¤
    10: 'remote',       # ë¦¬ëª¨ì»¨
    11: 'keyboard',     # í‚¤ë³´ë“œ
    12: 'cell phone',   # íœ´ëŒ€í°
    13: 'chair',        # ì˜ì
    14: 'couch',        # ì†ŒíŒŒ
    15: 'bed',          # ì¹¨ëŒ€
    16: 'dining table', # ì‹íƒ
    17: 'toilet',       # í™”ì¥ì‹¤
    18: 'tv'            # TV
}

# ìœ„í—˜ ë“±ê¸‰ ë¶„ë¥˜
DANGER_LEVELS = {
    'HIGH': ['knife', 'scissors'],           # ë†’ìŒ - ìœ„í—˜ë¬¼ì²´
    'MEDIUM': ['person'],                    # ì¤‘ê°„ - ì‚¬ëŒ
    'LOW': ['cat', 'dog'],                   # ë‚®ìŒ - ë°˜ë ¤ë™ë¬¼
    'VALUABLE': ['laptop', 'cell phone', 'backpack', 'handbag', 'suitcase'],  # ê·€ì¤‘í’ˆ
    'NORMAL': ['chair', 'couch', 'bed', 'dining table', 'toilet', 'tv', 'mouse', 'remote', 'keyboard']  # ì¼ë°˜
}

def get_danger_level(class_name):
    """ê°ì²´ì˜ ìœ„í—˜ ë“±ê¸‰ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    for level, classes in DANGER_LEVELS.items():
        if class_name in classes:
            return level
    return 'UNKNOWN'

def get_color_by_danger(danger_level):
    """ìœ„í—˜ ë“±ê¸‰ì— ë”°ë¥¸ ìƒ‰ìƒì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    colors = {
        'HIGH': (0, 0, 255),      # ë¹¨ê°•
        'MEDIUM': (0, 165, 255),  # ì£¼í™©
        'LOW': (0, 255, 0),       # ì´ˆë¡
        'VALUABLE': (255, 0, 255), # ìí™
        'NORMAL': (255, 255, 0),   # ì²­ë¡
        'UNKNOWN': (128, 128, 128) # íšŒìƒ‰
    }
    return colors.get(danger_level, (128, 128, 128))

class HomeCCTVDetector:
    def __init__(self, model_path='best.pt', conf_threshold=0.25):
        """
        í™ˆ CCTV ê°ì²´ ì¸ì‹ê¸° ì´ˆê¸°í™”
        
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        print(f"ğŸ” ëª¨ë¸ ë¡œë”© ì¤‘: {model_path}")
        self.model = YOLO(model_path)
        self.conf_threshold = conf_threshold
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ì‹ ë¢°ë„ ì„ê³„ê°’: {conf_threshold})")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ–¥ï¸  ì‚¬ìš© ì¥ì¹˜: {self.device}")

    def detect_objects(self, image, draw_boxes=True):
        """
        ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (numpy array)
            draw_boxes: ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì—¬ë¶€
            
        Returns:
            ê²°ê³¼ ì´ë¯¸ì§€, íƒì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        # ì˜ˆì¸¡ ìˆ˜í–‰
        results = self.model(image, conf=self.conf_threshold, device=self.device)
        
        detected_objects = []
        result_image = image.copy()
        
        # ê²°ê³¼ ì²˜ë¦¬
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # ë°•ìŠ¤ ì •ë³´ ì¶”ì¶œ
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])
                    
                    # í´ë˜ìŠ¤ ì´ë¦„ ë° ìœ„í—˜ ë“±ê¸‰
                    class_name = HOME_CCTV_CLASSES.get(class_id, 'Unknown')
                    danger_level = get_danger_level(class_name)
                    
                    # íƒì§€ ì •ë³´ ì €ì¥
                    detected_objects.append({
                        'class_name': class_name,
                        'confidence': confidence,
                        'bbox': (int(x1), int(y1), int(x2), int(y2)),
                        'danger_level': danger_level
                    })
                    
                    if draw_boxes:
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        color = get_color_by_danger(danger_level)
                        
                        # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        cv2.rectangle(result_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                        
                        # ë¼ë²¨ í…ìŠ¤íŠ¸
                        label = f"{class_name} {confidence:.2f} [{danger_level}]"
                        
                        # í…ìŠ¤íŠ¸ ë°°ê²½
                        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                        cv2.rectangle(result_image, (int(x1), int(y1) - text_height - 10), 
                                    (int(x1) + text_width, int(y1)), color, -1)
                        
                        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                        cv2.putText(result_image, label, (int(x1), int(y1) - 5),
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return result_image, detected_objects

    def test_image(self, image_path, save_result=True):
        """ì´ë¯¸ì§€ íŒŒì¼ í…ŒìŠ¤íŠ¸"""
        print(f"ğŸ“¸ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸: {image_path}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return
        
        # ê°ì²´ ì¸ì‹
        start_time = time.time()
        result_image, detections = self.detect_objects(image)
        inference_time = time.time() - start_time
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"â±ï¸  ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ")
        print(f"ğŸ¯ íƒì§€ëœ ê°ì²´ ìˆ˜: {len(detections)}")
        
        for i, obj in enumerate(detections, 1):
            print(f"  {i}. {obj['class_name']} (ì‹ ë¢°ë„: {obj['confidence']:.3f}, ìœ„í—˜ë„: {obj['danger_level']})")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        if save_result:
            output_path = Path(image_path).stem + "_result.jpg"
            cv2.imwrite(output_path, result_image)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        
        # ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
        cv2.imshow('í™ˆ CCTV ê°ì²´ ì¸ì‹ ê²°ê³¼', result_image)
        print("âŒ ì¢…ë£Œí•˜ë ¤ë©´ ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ì„¸ìš”...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()

    def test_video(self, video_path, save_result=True):
        """ë¹„ë””ì˜¤ íŒŒì¼ í…ŒìŠ¤íŠ¸"""
        print(f"ğŸ¬ ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸: {video_path}")
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return
        
        # ë¹„ë””ì˜¤ ì •ë³´
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps}FPS, {total_frames}í”„ë ˆì„")
        
        # ê²°ê³¼ ë¹„ë””ì˜¤ ì €ì¥ ì„¤ì •
        if save_result:
            output_path = Path(video_path).stem + "_result.mp4"
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # ê°ì²´ ì¸ì‹
            result_frame, detections = self.detect_objects(frame)
            
            # í”„ë ˆì„ ì •ë³´ í‘œì‹œ
            info_text = f"Frame: {frame_count}/{total_frames} | Objects: {len(detections)}"
            cv2.putText(result_frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # ê²°ê³¼ ì €ì¥
            if save_result:
                out.write(result_frame)
            
            # í™”ë©´ í‘œì‹œ
            cv2.imshow('í™ˆ CCTV ë¹„ë””ì˜¤ ë¶„ì„', result_frame)
            
            # ESC í‚¤ë¡œ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == 27:  # ESC key
                break
            
            # ì§„í–‰ë¥  ì¶œë ¥ (10í”„ë ˆì„ë§ˆë‹¤)
            if frame_count % 10 == 0:
                progress = (frame_count / total_frames) * 100
                elapsed = time.time() - start_time
                fps_current = frame_count / elapsed
                print(f"ì§„í–‰ë¥ : {progress:.1f}% ({fps_current:.1f} FPS)")
        
        # ì •ë¦¬
        cap.release()
        if save_result:
            out.release()
            print(f"ğŸ’¾ ê²°ê³¼ ë¹„ë””ì˜¤ ì €ì¥: {output_path}")
        
        cv2.destroyAllWindows()
        
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time
        print(f"âœ… ë¹„ë””ì˜¤ ë¶„ì„ ì™„ë£Œ!")
        print(f"â±ï¸  ì´ ì‹œê°„: {total_time:.1f}ì´ˆ, í‰ê·  FPS: {avg_fps:.1f}")

    def test_webcam(self):
        """ì›¹ìº  ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        print("ğŸ“¹ ì›¹ìº  ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        print("âŒ ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”")
        
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ì›¹ìº  í•´ìƒë„ ì„¤ì •
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        frame_count = 0
        start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # ê°ì²´ ì¸ì‹
            result_frame, detections = self.detect_objects(frame)
            
            # FPS ê³„ì‚°
            current_time = time.time()
            elapsed = current_time - start_time
            fps = frame_count / elapsed if elapsed > 0 else 0
            
            # ì •ë³´ í‘œì‹œ
            info_text = f"FPS: {fps:.1f} | Objects: {len(detections)}"
            cv2.putText(result_frame, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # íƒì§€ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
            y_offset = 60
            for obj in detections:
                obj_text = f"{obj['class_name']} ({obj['confidence']:.2f}) - {obj['danger_level']}"
                cv2.putText(result_frame, obj_text, (10, y_offset), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                y_offset += 25
            
            # í™”ë©´ í‘œì‹œ
            cv2.imshow('í™ˆ CCTV ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§', result_frame)
            
            # 'q' í‚¤ë¡œ ì¢…ë£Œ
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        print("âœ… ì›¹ìº  í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")

def main():
    parser = argparse.ArgumentParser(description='í™ˆ CCTV ê°ì²´ ì¸ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--model', default='best.pt', help='ëª¨ë¸ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--image', help='í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ íŒŒì¼')
    parser.add_argument('--video', help='í…ŒìŠ¤íŠ¸í•  ë¹„ë””ì˜¤ íŒŒì¼')
    parser.add_argument('--webcam', action='store_true', help='ì›¹ìº  ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--conf', type=float, default=0.25, help='ì‹ ë¢°ë„ ì„ê³„ê°’')
    
    args = parser.parse_args()
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    detector = HomeCCTVDetector(args.model, args.conf)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if args.image:
        detector.test_image(args.image)
    elif args.video:
        detector.test_video(args.video)
    elif args.webcam:
        detector.test_webcam()
    else:
        print("ì‚¬ìš©ë²•:")
        print("ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸: python test_model.py --image test.jpg")
        print("ë¹„ë””ì˜¤ í…ŒìŠ¤íŠ¸: python test_model.py --video test.mp4")
        print("ì›¹ìº  í…ŒìŠ¤íŠ¸: python test_model.py --webcam")

if __name__ == "__main__":
    main() 